{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:12345/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from flask import Flask, request, jsonify\n",
    "import traceback\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pipelines.DataPipeline import DataPipeline\n",
    "from utils.Common import Config\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def predict(json_, classifier):\n",
    "    try:\n",
    "        \n",
    "        if classifier:\n",
    "            print(dir(classifier))\n",
    "            # convert to dataframe\n",
    "            df = pd.DataFrame(json_)\n",
    "            X=df[Config.cat_attribs + Config.num_attribs + Config.binary_columns]\n",
    "            \n",
    "               \n",
    "            # pass feature to pipeline and convert it to numerical data          \n",
    "            X = datapipeline.transform(X)\n",
    "            X = pd.DataFrame(X)\n",
    "            prediction = list(classifier.predict(X))\n",
    "            print({\"prediction\": str(prediction)})\n",
    "            return jsonify({\"prediction\": str(prediction)})\n",
    "        else:\n",
    "            print(\"Train the model first\")\n",
    "            return \"No model here to use\"\n",
    "    except:\n",
    "        return jsonify({\"trace\": traceback.format_exc()})\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "\n",
    "# use decorator pattern for the route\n",
    "@app.route(\"/predict/svc\", methods=[\"GET\", \"POST\"])\n",
    "def predictSVC():\n",
    "    json_ = request.json\n",
    "    print(json_)\n",
    "    result = predict(json_, svc_clf)\n",
    "    return result\n",
    "\n",
    "\n",
    "# use decorator pattern for the route\n",
    "@app.route(\"/predict/rf\", methods=[\"GET\", \"POST\"])\n",
    "def predictRF():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, rf_clf)\n",
    "    return result\n",
    "\n",
    "\n",
    "# use decorator pattern for the route\n",
    "@app.route(\"/predict/knn\", methods=[\"GET\", \"POST\"])\n",
    "def predictKNN():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, knn_clf)\n",
    "    return result\n",
    "\n",
    "\n",
    "# use decorator pattern for the route\n",
    "@app.route(\"/predict/ada\", methods=[\"GET\", \"POST\"])\n",
    "def predictAda():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, ada_clf)\n",
    "    return result\n",
    "\n",
    "@app.route(\"/predict/vote_hard\", methods=[\"GET\", \"POST\"])\n",
    "def predictVotingHard():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, voting_hard_clf)\n",
    "    return result\n",
    "\n",
    "@app.route(\"/predict/vote_soft\", methods=[\"GET\", \"POST\"])\n",
    "def predictVotingSoft():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, voting_soft_clf)\n",
    "    return result\n",
    "\n",
    "@app.route(\"/spatialquery\", methods=[\"GET\", \"POST\"])\n",
    "def getCoordinates():\n",
    "    json_ = request.json\n",
    "    # load data from json_\n",
    "    polyjson = json.loads(json_)\n",
    "    polygon =  gpd.GeoDataFrame.from_features(polyjson, crs='EPSG:4326')\n",
    "    polygon = polygon.to_crs('EPSG:4326')     \n",
    "    points = raw_data.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(raw_data, geometry=points, crs='EPSG:4326')\n",
    "    contains = gdf.within(polygon.geometry.iloc[0])\n",
    "    result_points = raw_data[contains][['INDEX_','LONGITUDE','LATITUDE']].to_json(orient='records')\n",
    "    return result_points\n",
    "\n",
    "try:\n",
    "    port = int(sys.argv[1])  # This is for a command-line input\n",
    "except:\n",
    "    port = 12345  # If you don't provide any port the port will be set to 12345\n",
    "    \n",
    "\n",
    "datapipeline = joblib.load(\"../models/datapipeline.pkl\")\n",
    "svc_clf = joblib.load(\"../models/best_model_svc.pkl\")\n",
    "rf_clf = joblib.load(\"../models/best_model_random_forest.pkl\")\n",
    "knn_clf = joblib.load(\"../models/best_model_knn.pkl\")\n",
    "ada_clf = joblib.load(\"../models/best_model_adaboost.pkl\")\n",
    "voting_hard_clf = joblib.load(\"../models/best_model_voting_hard.pkl\")\n",
    "voting_soft_clf = joblib.load(\"../models/best_model_voting_soft.pkl\")\n",
    "raw_data = pd.read_csv(\"../data/raw/KSI.csv\")\n",
    "\n",
    "\n",
    "print(\"Model loaded\")\n",
    "app.run(port=port)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on KSI prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.Preprocessing import Preprocessing\n",
    "\n",
    "\n",
    "svc_clf = joblib.load(\"../models/best_model_svc.pkl\")\n",
    "rf_clf = joblib.load(\"../models/best_model_random_forest.pkl\")\n",
    "knn_clf = joblib.load(\"../models/best_model_knn.pkl\")\n",
    "#json_ = [{'VEHTYPE': 'Bicycle', 'ROAD_CLASS': 'Expressway', 'LOCCOORD': '', 'DISTRICT': 'North York', 'TRAFFCTL': 'No Control', 'LIGHT': 'Daylight', 'RDSFCOND': 'Dry', 'INVTYPE': 'Motorcycle Driver', 'IMPACTYPE': 'Approaching', 'INVAGE': '70 to 74', 'YEAR': 2023, 'TIME': 1420, 'LATITUDE': 43.785132, 'LONGITUDE': -79.164089, 'DATE': '2023/04/10 05:00:00+00', 'PEDESTRIAN': '', 'CYCLIST': 'Yes', 'AUTOMOBILE': '', 'TRUCK': '', 'TRSN_CITY_VEH': '', 'PASSENGER': '', 'SPEEDING': 'Yes', 'AG_DRIV': ''}]\n",
    "json_ = [{'VEHTYPE': 'Bicycle', 'ROAD_CLASS': 'Expressway', 'LOCCOORD': 'Intersection', 'DISTRICT': 'North York', 'TRAFFCTL': 'No Control', 'LIGHT': 'Daylight', 'RDSFCOND': 'Dry', 'INVTYPE': 'Motorcycle Driver', 'IMPACTYPE': 'Approaching', 'INVAGE': '70 to 74', 'YEAR': 2023, 'TIME': 14, 'LATITUDE': 43.785132, 'LONGITUDE': -79.164089, 'MONTH': 4, 'DAY': 1, 'PEDESTRIAN': 0, 'CYCLIST': 1, 'AUTOMOBILE': 0, 'TRUCK': 0, 'TRSN_CITY_VEH': 0, 'PASSENGER': 0, 'SPEEDING': 1, 'AG_DRIV': 0}]\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(json_)\n",
    "X = df[Config.cat_attribs + Config.num_attribs+ Config.binary_columns]\n",
    "\n",
    "# pass feature to pipeline and convert it to numerical data\n",
    "datapipeline = joblib.load(\"../models/datapipeline.pkl\")\n",
    "X = datapipeline.transform(df)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "Y_pred = svc_clf.predict(X)\n",
    "print(Y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert polygon to json string\n",
    "Coordinate pair Format: (lon,lat)\n",
    "\n",
    "Coordinates of a polygon should be [(1,1),(1,2),(2,2),(2,1),(1,1)]\n",
    "\n",
    "where (1,1) is the start and end point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, mapping\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# create a Polygon object\n",
    "polygon_coords = [(-79.46321135810555, 43.72212571942046), (-79.29704314521611, 43.79601968703417)\n",
    "                  , (-79.29017669013803, 43.70128006022296), (-79.46801787666021, 43.66304418751821), (-79.46321135810555, 43.72212571942046)]\n",
    "polygon = gpd.GeoSeries([Polygon(polygon_coords)], crs='EPSG:4326')\n",
    "polygon = polygon.to_crs('EPSG:4326')\n",
    "\n",
    "json_str = polygon.to_json()\n",
    "\n",
    "print(json_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on the Spatial Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "def getCoordinates():\n",
    "    print(json_)\n",
    "    # load data from json_\n",
    "    polyjson = json.loads(json_)\n",
    "    polygon =  gpd.GeoDataFrame.from_features(polyjson, crs='EPSG:4326')\n",
    "    polygon = polygon.to_crs('EPSG:4326')     \n",
    "    points = raw_data.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(raw_data, geometry=points, crs='EPSG:4326')\n",
    "    contains = gdf.within(polygon.geometry.iloc[0])\n",
    "    result_points = raw_data[contains][['INDEX_','LONGITUDE','LATITUDE']].to_json(orient='records')\n",
    "    return result_points\n",
    "\n",
    "  \n",
    "json_ = '{\"type\": \"FeatureCollection\", \"features\": [{\"id\": \"0\", \"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[-79.46321135810555, 43.72212571942046], [-79.29704314521611, 43.79601968703417], [-79.29017669013803, 43.70128006022296], [-79.46801787666021, 43.66304418751821], [-79.46321135810555, 43.72212571942046]]]}, \"bbox\": [-79.46801787666021, 43.66304418751821, -79.29017669013803, 43.79601968703417]}], \"bbox\": [-79.46801787666021, 43.66304418751821, -79.29017669013803, 43.79601968703417]}'\n",
    "raw_data = pd.read_csv(\"../data/raw/KSI.csv\")\n",
    "points = getCoordinates()\n",
    "print(points)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Query (get point within a polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "# create a GeoSeries object for the polygon\n",
    "polygon_coords = [(-79.46321135810555, 43.72212571942046), (-79.29704314521611, 43.79601968703417)\n",
    "                  , (-79.29017669013803, 43.70128006022296), (-79.46801787666021, 43.66304418751821), (-79.46321135810555, 43.72212571942046)]\n",
    "polygon = gpd.GeoSeries([Polygon(polygon_coords)], crs='EPSG:4326')\n",
    "polygon = polygon.to_crs('EPSG:4326')\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv(\"../data/raw/KSI.csv\")\n",
    "points = raw_data.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
    "gdf = gpd.GeoDataFrame(raw_data, geometry=points, crs='EPSG:4326')\n",
    "contains = gdf.within(polygon.geometry.iloc[0])\n",
    "\n",
    "print(raw_data[contains][['INDEX_','LONGITUDE','LATITUDE']].to_json(orient='records'))\n",
    "#raw_data[(lat1 <= raw_data.LATITUDE <= lat2) and lon1 <= raw_data.LONGITUDE <= lon2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
