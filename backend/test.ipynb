{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from flask import Flask, request, jsonify\n",
    "import traceback\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pipelines.DataPipeline import DataPipeline\n",
    "from utils.Common import Config\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model_columns = [Config.cat_attribs + Config.num_attribs + Config.binary_columns]\n",
    "\n",
    "def predict(json_, classifier):\n",
    "    try:\n",
    "        if classifier:\n",
    "            # convert to dataframe\n",
    "            new_df = pd.DataFrame(json_)\n",
    "            new_df = new_df.reindex(columns=model_columns, fill_value=0)\n",
    "            print(new_df)\n",
    "\n",
    "            # ass feature to pipeline and convert it to numerical data\n",
    "            dc = DataPipeline(Config.num_attribs,Config.cat_attribs)\n",
    "            X = dc.process(X)\n",
    "\n",
    "            prediction = list(classifier.predict(X))\n",
    "            print({'prediction': str(prediction)})\n",
    "            return jsonify({'prediction': str(prediction)})\n",
    "        else:\n",
    "            print ('Train the model first')\n",
    "            return ('No model here to use')\n",
    "    except:\n",
    "        return jsonify({'trace': traceback.format_exc()})    \n",
    "\n",
    "@app.route(\"/predict/svc\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictSVC():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, svc_clf)\n",
    "    return result\n",
    "\n",
    "@app.route(\"/predict/rf\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictRF():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, rf_clf)\n",
    "    return result\n",
    "    \n",
    "@app.route(\"/predict/knn\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictKNN():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, knn_clf)\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        port = int(sys.argv[1]) # This is for a command-line input\n",
    "\n",
    "        print ('Model loaded')\n",
    "    except:\n",
    "        port = 12345 # If you don't provide any port the port will be set to 12345\n",
    "    svc_clf = joblib.load('../models/best_model_svc.pkl')\n",
    "    rf_clf = joblib.load('../models/best_model_random_forest.pkl')\n",
    "    knn_clf = joblib.load('../models/best_model_knn.pkl')\n",
    "    app.run(port=port, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:12345/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from flask import Flask, request, jsonify\n",
    "import traceback\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "model_columns = [Config.cat_attribs + Config.num_attribs + Config.binary_columns]\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def predict(json_, classifier):\n",
    "    try:\n",
    "        if classifier:\n",
    "            # convert to dataframe\n",
    "            new_df = pd.DataFrame(json_)\n",
    "            new_df = new_df.reindex(columns=model_columns, fill_value=0)\n",
    "            print(new_df)\n",
    "\n",
    "            # ass feature to pipeline and convert it to numerical data\n",
    "            dc = DataPipeline(Config.num_attribs,Config.cat_attribs)\n",
    "            X = dc.process(X)\n",
    "\n",
    "            prediction = list(classifier.predict(X))\n",
    "            print({'prediction': str(prediction)})\n",
    "            return jsonify({'prediction': str(prediction)})\n",
    "        else:\n",
    "            print ('Train the model first')\n",
    "            return ('No model here to use')\n",
    "    except:\n",
    "        return jsonify({'trace': traceback.format_exc()}) \n",
    "    \n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello World!'\n",
    "\n",
    "\n",
    "@app.route(\"/predict/svc\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictSVC():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, svc_clf)\n",
    "    return result\n",
    "\n",
    "@app.route(\"/predict/rf\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictRF():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, rf_clf)\n",
    "    return result\n",
    "    \n",
    "@app.route(\"/predict/knn\", methods=['GET','POST']) #use decorator pattern for the route\n",
    "def predictKNN():\n",
    "    json_ = request.json\n",
    "    result = predict(json_, knn_clf)\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        port = int(sys.argv[1]) # This is for a command-line input       \n",
    "    except:\n",
    "        port = 12345 # If you don't provide any port the port will be set to 12345\n",
    "        \n",
    "    svc_clf = joblib.load('../models/best_model_svc.pkl')\n",
    "    rf_clf = joblib.load('../models/best_model_random_forest.pkl')\n",
    "    knn_clf = joblib.load('../models/best_model_knn.pkl')\n",
    "    print ('Model loaded')\n",
    "    app.run(port=port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
